{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open( '/share/hel/datasets/jobiqo/talent.com/JobRec/unbalanced_test.pkl', 'rb') as file:\n",
    "    test_dicts = pickle.load(file)\n",
    "bios_test = pd.DataFrame(test_dicts).reset_index()\n",
    "bios_test = bios_test.drop('index', axis=1)\n",
    "\n",
    "\n",
    "with open( '/share/hel/datasets/jobiqo/talent.com/JobRec/uk_jobs.pkl', 'rb') as file:\n",
    "    dicts = pickle.load(file)\n",
    "uk_jobs = pd.DataFrame(dicts).reset_index()\n",
    "uk_jobs = uk_jobs.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/share/rk8/home/deepak/JobAd_Rec/Models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg Neutrality score @10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neutrality(file):\n",
    "    neutrality_score = 0 \n",
    "    for i in file:\n",
    "        neutrality_score = neutrality_score + uk_jobs.iloc[i['corpus_id'][:10]]['neutrality'].mean()\n",
    "    return neutrality_score/len(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "result = {}\n",
    "for model in os.listdir(base_path):\n",
    "    if 'shahed_result.pkl' in model:\n",
    "        with open(base_path+model, 'rb') as file:\n",
    "            result[model.replace('shahed_result.pkl','')] = get_neutrality(pickle.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result = {'0.0':[], '0.1':[], '0.2':[], '0.3':[], '0.4':[],'0.6':[],'0.8':[], '1.0':[]}\n",
    "\n",
    "\n",
    "for key in result.keys():\n",
    "    for new_key in new_result.keys():\n",
    "        if new_key in key:\n",
    "            new_result[new_key].append(result[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.0', 0.9531080070241037)\n",
      "('0.1', 0.9546807154010772)\n",
      "('0.2', 0.9544876859445962)\n",
      "('0.3', 0.9575129559801275)\n",
      "('0.4', 0.9561346544970625)\n",
      "('0.6', 0.9576823867542487)\n",
      "('0.8', 0.9613789789099404)\n",
      "('1.0', 0.9775374115320563)\n"
     ]
    }
   ],
   "source": [
    "for key in new_result.keys():\n",
    "    print((key, sum(new_result[key][1:])/len(new_result[key][1:])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "def get_ndcg(dicts):\n",
    "    ndcg = []\n",
    "    for i in range(len(bios_test)):\n",
    "        ndcg.append(ndcg_score(np.asarray([uk_jobs.iloc[dicts[i]['corpus_id']]['title'].apply(lambda x: 1 if x==bios_test['raw_title'][i] else 0)]),[dicts[i]['scores']],k=10))\n",
    "    \n",
    "    return sum(ndcg)/len(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline nDCG is 0.745 with std 0.014\n"
     ]
    }
   ],
   "source": [
    "Models = ['1500_distilroberta-base_2024-01-25_02-54-56','1390_distilroberta-base_2024-01-25_02-54-56','5915_distilroberta-base_2024-01-25_02-54-56']\n",
    "\n",
    "result = []\n",
    "\n",
    "for model in Models:\n",
    "    with open(base_path+model+'result.pkl', 'rb') as file:\n",
    "        result.append(get_ndcg(pickle.load(file)))\n",
    "\n",
    "print('Baseline nDCG is {:.3f} with std {:.3f}'.format(np.mean(np.array(result)),np.std(np.array(result))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline with red words masked during testing gives nDCG is 0.633 with std 0.005\n"
     ]
    }
   ],
   "source": [
    "Models = ['1500_distilroberta-base_2024-01-25_02-54-56','1390_distilroberta-base_2024-01-25_02-54-56','5915_distilroberta-base_2024-01-25_02-54-56']\n",
    "\n",
    "result = []\n",
    "\n",
    "for model in Models:\n",
    "    with open(base_path+model+'mask_result.pkl', 'rb') as file:\n",
    "        result.append(get_ndcg(pickle.load(file)))\n",
    "\n",
    "print('Baseline with red words masked during testing gives nDCG is {:.3f} with std {:.3f}'.format(np.mean(np.array(result)),np.std(np.array(result))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nDCG separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "def get_ndcg_separate(dicts):\n",
    "    ndcg = []\n",
    "    for i in range(len(bios_test)):\n",
    "        ndcg.append(ndcg_score(np.asarray([uk_jobs.iloc[dicts[i]['corpus_id']]['title'].apply(lambda x: 1 if x==bios_test['raw_title'][i] else 0)]),[dicts[i]['scores']],k=10))\n",
    "    \n",
    "\n",
    "    male_ndcg = [ndcg[i] for i in bios_test[bios_test.gender =='M'].index]\n",
    "    female_ndcg = [ndcg[i] for i in bios_test[bios_test.gender =='F'].index]\n",
    "    \n",
    "    if len(male_ndcg)>0:\n",
    "        male_ndcg =sum(male_ndcg)/len(male_ndcg)\n",
    "    else:\n",
    "        male_ndcg = 0\n",
    "    if len(female_ndcg)>0:\n",
    "        female_ndcg =sum(female_ndcg)/len(female_ndcg)\n",
    "    else:\n",
    "        female_ndcg = 0\n",
    "     \n",
    "    return (male_ndcg, female_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline male nDCG is 0.737 with std 0.016\n",
      "Baseline female nDCG is 0.752 with std 0.014\n",
      "The gap is 0.015\n"
     ]
    }
   ],
   "source": [
    "Models = ['1500_distilroberta-base_2024-01-25_02-54-56','1390_distilroberta-base_2024-01-25_02-54-56','5915_distilroberta-base_2024-01-25_02-54-56']\n",
    "\n",
    "result_male = []\n",
    "result_female = []\n",
    "\n",
    "for model in Models:\n",
    "    with open(base_path+model+'result.pkl', 'rb') as file:\n",
    "        m,f = get_ndcg_separate(pickle.load(file))\n",
    "        result_male.append(m)\n",
    "        result_female.append(f)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Baseline male nDCG is {:.3f} with std {:.3f}\".format(np.mean(np.array(result_male)),np.std(np.array(result_male))))\n",
    "print(\"Baseline female nDCG is {:.3f} with std {:.3f}\".format(np.mean(np.array(result_female)),np.std(np.array(result_female))))\n",
    "print('The gap is {:.3f}'.format(abs(np.mean(np.array(result_male))-np.mean(np.array(result_female)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline with red words masked during testing gives male nDCG is 0.642 with std 0.003\n",
      "Baseline with red words masked during testing gives female nDCG is 0.624 with std 0.008\n",
      "The gap is 0.018\n"
     ]
    }
   ],
   "source": [
    "Models = ['1500_distilroberta-base_2024-01-25_02-54-56','1390_distilroberta-base_2024-01-25_02-54-56','5915_distilroberta-base_2024-01-25_02-54-56']\n",
    "\n",
    "result_male = []\n",
    "result_female = []\n",
    "\n",
    "for model in Models:\n",
    "    with open(base_path+model+'mask_result.pkl', 'rb') as file:\n",
    "        m,f = get_ndcg_separate(pickle.load(file))\n",
    "        result_male.append(m)\n",
    "        result_female.append(f)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Baseline with red words masked during testing gives male nDCG is {:.3f} with std {:.3f}\".format(np.mean(np.array(result_male)),np.std(np.array(result_male))))\n",
    "print(\"Baseline with red words masked during testing gives female nDCG is {:.3f} with std {:.3f}\".format(np.mean(np.array(result_female)),np.std(np.array(result_female))))\n",
    "print('The gap is {:.3f}'.format(abs(np.mean(np.array(result_male))-np.mean(np.array(result_female)))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change in ranking when using Counterfactual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the input create counterfactual and get the ranking. You have 2 set of ranking original and couterfactual. Find original vs counterfactual list difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_conter()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPRP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is changing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attacker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who is higher?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evonlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
